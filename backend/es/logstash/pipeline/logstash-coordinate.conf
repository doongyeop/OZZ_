input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/mysql-connector-java-8.3.0.jar"
    jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://mysql:3306/ozz"
    jdbc_user => "${DB_USER}"
    jdbc_password => "${DB_PW}"
    jdbc_paging_enabled => true
    schedule => "* * * * *"  # Every minute
    statement => "SELECT
                    coordinate_id,
                    CAST(style AS UNSIGNED) AS style,
                    name, user_id, image_file_id
                 FROM coordinate
                 WHERE updated_date > :sql_last_value"
    use_column_value => true
    tracking_column => "updated_date"
    tracking_column_type => "timestamp"
  }
}

filter {
  ruby {
    code => '
      require "net/http"
      require "uri"
      require "json"

      uri = URI.parse("http://ozz-ai:#{ENV["AI_PORT"]}/vectorize")
      request = Net::HTTP::Post.new(uri, "Content-Type" => "application/json")
      request.body = {"text" => event.get("name")}.to_json

      response = Net::HTTP.start(uri.hostname, uri.port) do |http|
        http.request(request)
      end

      if response.code == "200"
        event.set("vector", JSON.parse(response.body)["vector"])
        event.set("status", "published")
      else
        event.set("vector", "error")
        event.set("status", "error")
      end
    '
  }
}

output {
  stdout { codec => rubydebug }
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ozz_coordinate"
    document_id => "%{coordinate_id}"
  }
}